{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from nltk import tag\n", "import pandas as pd\n", "import nltk\n", "from gensim.test.utils import common_texts\n", "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n", "from doc2vec import Doc2VecModel,create_corpus,intents"]}, {"cell_type": "markdown", "metadata": {}, "source": ["retrieve the saved model from the pickle file<br>\n", "retrieve the tagged document corpus of the model<br>\n", "get the list of intents from the doc2vec<br>\n", "for each intent key, get the top 1000 most similar vector documents <br>\n", "retrieve those docs from tagged docs corpus by using the index of the vecdoc <br>\n", "create intent file dataset and save to yaml"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rint(\"here in cluster\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model=Doc2Vec.load(\"Models/Doc2Vec.model\")\n", "corpus=create_corpus('Datasets/required_dataset.pkl')\n", "tagged_doc=[TaggedDocument(words=doc, tags=[str(i)]) for i, doc in enumerate(corpus)]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["function that retrieves documents from the corpus based on the tags and groups them<br>\n", "according to their respective intents<br>\n", "returns a pandas dataframe as training data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def generate_training_data():\n", "    training_dict={}\n", "    for key in intents:\n", "        doc_lst=[]\n", "        inferred_vector=model.infer_vector(nltk.word_tokenize(intents[key]))\n", "        sims=model.dv.most_similar(inferred_vector,topn=1000)\n", "        for item in sims:\n", "            index=int(item[0])\n", "            doc_lst.append(tagged_doc[index][0])\n", "            #doc_lst=doc_lst+tagged_doc[index][0]\n", "        #training_dict[key]=list(set(doc_lst))\n", "        training_dict[key]=doc_lst\n", "    df_train=pd.DataFrame(list(training_dict.items()),columns=['Intents', 'Documents'])\n", "    return df_train"]}, {"cell_type": "markdown", "metadata": {}, "source": ["df=generate_training_data()<br>\n", "print(df['Documents'][5])"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}